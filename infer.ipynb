{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45edcb91-6713-40b8-819b-12415cc56449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@author yuetian\n",
    "from torchvision.ops.boxes import batched_nms\n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models.prob_deformable_detr import build\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from main_open_world import get_datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import datasets.samplers as samplers\n",
    "from util.misc import init_distributed_mode, collate_fn, MetricLogger, SmoothedValue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6733c61d-e40d-4689-be29-403968b96ce8",
   "metadata": {},
   "source": [
    "# Reference: params setting for task 1 eval\n",
    "```\n",
    "Namespace(lr=0.0002, lr_backbone_names=['backbone.0'], lr_backbone=2e-05, lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, batch_size=5, weight_decay=0.0001, epochs=191, lr_drop=35, lr_drop_epochs=None, clip_max_norm=0.1, sgd=False, with_box_refine=False, two_stage=False, masks=False, backbone='dino_resnet50', frozen_weights=None, dilation=False, position_embedding='sine', position_embedding_scale=6.283185307179586, num_feature_levels=4, enc_layers=6, dec_layers=6, dim_feedforward=1024, hidden_dim=256, dropout=0.1, nheads=8, num_queries=100, dec_n_points=4, enc_n_points=4, aux_loss=True, set_cost_class=2, set_cost_bbox=5, set_cost_giou=2, cls_loss_coef=2, bbox_loss_coef=5, giou_loss_coef=2, focal_alpha=0.25, coco_panoptic_path=None, remove_difficult=False, output_dir='exps/SOWODB/PROB/eval', device='cuda', seed=42, resume='', start_epoch=0, eval=True, viz=False, eval_every=5, num_workers=3, cache_mode=False, PREV_INTRODUCED_CLS=0, CUR_INTRODUCED_CLS=19, unmatched_boxes=False, top_unk=5, featdim=1024, invalid_cls_logits=False, NC_branch=False, bbox_thresh=0.3, pretrain='exps/SOWODB/PROB/t1.pth', nc_loss_coef=2, train_set='owdetr_t1_train', test_set='owdetr_test', num_classes=81, nc_epoch=0, dataset='OWDETR', data_root='/training_data_2/yuetian/OWOD', unk_conf_w=1.0, model_type='prob', wandb_name='prob_original', wandb_project='', obj_loss_coef=0.0008, obj_temp=1.3, freeze_prob_model=False, num_inst_per_class=50, exemplar_replay_selection=False, exemplar_replay_max_length=10000000000.0, exemplar_replay_dir='', exemplar_replay_prev_file='', exemplar_replay_cur_file='', exemplar_replay_random=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1530a3a5-d9a3-4423-8145-10fa775523ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    'lr': 0.0002, 'lr_backbone_names': ['backbone.0'], \n",
    "    'lr_backbone': 2e-05, 'lr_linear_proj_names': ['reference_points', 'sampling_offsets'], \n",
    "    'lr_linear_proj_mult': 0.1, 'batch_size': 1, 'weight_decay': 0.0001, 'epochs': 191, 'lr_drop': 35, \n",
    "    'lr_drop_epochs': None, 'clip_max_norm': 0.1, 'sgd': False, 'with_box_refine': False, 'two_stage': False, \n",
    "    'masks': False, 'backbone': 'dino_resnet50', 'frozen_weights': None, 'dilation': False, 'position_embedding': 'sine', \n",
    "    'position_embedding_scale': 6.283185307179586, 'num_feature_levels': 4, 'enc_layers': 6, 'dec_layers': 6, \n",
    "    'dim_feedforward': 1024, 'hidden_dim': 256, 'dropout': 0.1, 'nheads': 8, 'num_queries': 100, \n",
    "    'dec_n_points': 4, 'enc_n_points': 4, 'aux_loss': True, 'set_cost_class': 2, 'set_cost_bbox': 5, \n",
    "    'set_cost_giou': 2, 'cls_loss_coef': 2, 'bbox_loss_coef': 5, 'giou_loss_coef': 2, \n",
    "    'focal_alpha': 0.25, 'coco_panoptic_path': None, 'remove_difficult': False, 'output_dir': 'exps/SOWODB/PROB/eval', \n",
    "    'device': 'cuda:2', 'seed': 42, 'resume': '', 'start_epoch': 0, 'eval': True, 'viz': False, 'eval_every': 5, 'num_workers': 3, \n",
    "    'cache_mode': False, 'PREV_INTRODUCED_CLS': 0, 'CUR_INTRODUCED_CLS': 19, 'unmatched_boxes': False, 'top_unk': 5, 'featdim': 1024, \n",
    "    'invalid_cls_logits': False, 'NC_branch': False, 'bbox_thresh': 0.3, 'pretrain': 'exps/SOWODB/PROB/t1.pth', 'nc_loss_coef': 2, \n",
    "    'train_set': 'owdetr_t1_train', 'test_set': 'owdetr_test', 'num_classes': 81, 'nc_epoch': 0, 'dataset': 'OWDETR', \n",
    "    'data_root': '/training_data_2/yuetian/OWOD', 'unk_conf_w': 1.0, 'model_type': 'prob', 'wandb_name': 'prob_original', \n",
    "    'wandb_project': '', 'obj_loss_coef': 0.0008, 'obj_temp': 1.3, 'freeze_prob_model': False, 'num_inst_per_class': 50, \n",
    "    'exemplar_replay_selection': False, 'exemplar_replay_max_length': 10000000000.0, 'exemplar_replay_dir': '', \n",
    "    'exemplar_replay_prev_file': '', 'exemplar_replay_cur_file': '', 'exemplar_replay_random': False\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e1a897-13c1-4f01-acd4-81246ce79794",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOC_CLASS_NAMES_COCOFIED = [\n",
    "    \"airplane\",  \"dining table\", \"motorcycle\",\n",
    "    \"potted plant\", \"couch\", \"tv\"\n",
    "]\n",
    "\n",
    "BASE_VOC_CLASS_NAMES = [\n",
    "    \"aeroplane\", \"diningtable\", \"motorbike\",\n",
    "    \"pottedplant\",  \"sofa\", \"tvmonitor\"\n",
    "]\n",
    "\n",
    "VOC_CLASS_NAMES = [\n",
    "    \"aeroplane\",\"bicycle\",\"bird\",\"boat\",\"bus\",\"car\",\n",
    "    \"cat\",\"cow\",\"dog\",\"horse\",\"motorbike\",\"sheep\",\"train\",\n",
    "    \"elephant\",\"bear\",\"zebra\",\"giraffe\",\"truck\",\"person\"\n",
    "]\n",
    "\n",
    "T2_CLASS_NAMES = [\n",
    "    \"traffic light\",\"fire hydrant\",\"stop sign\",\n",
    "    \"parking meter\",\"bench\",\"chair\",\"diningtable\",\n",
    "    \"pottedplant\",\"backpack\",\"umbrella\",\"handbag\",\n",
    "    \"tie\",\"suitcase\",\"microwave\",\"oven\",\"toaster\",\"sink\",\n",
    "    \"refrigerator\",\"bed\",\"toilet\",\"sofa\"\n",
    "]\n",
    "\n",
    "T3_CLASS_NAMES = [\n",
    "    \"frisbee\",\"skis\",\"snowboard\",\"sports ball\",\n",
    "    \"kite\",\"baseball bat\",\"baseball glove\",\"skateboard\",\n",
    "    \"surfboard\",\"tennis racket\",\"banana\",\"apple\",\"sandwich\",\n",
    "    \"orange\",\"broccoli\",\"carrot\",\"hot dog\",\"pizza\",\"donut\",\"cake\"\n",
    "]\n",
    "\n",
    "T4_CLASS_NAMES = [\n",
    "    \"laptop\",\"mouse\",\"remote\",\"keyboard\",\"cell phone\",\"book\",\n",
    "    \"clock\",\"vase\",\"scissors\",\"teddy bear\",\"hair drier\",\"toothbrush\",\n",
    "    \"wine glass\",\"cup\",\"fork\",\"knife\",\"spoon\",\"bowl\",\"tvmonitor\",\"bottle\"\n",
    "]\n",
    "\n",
    "UNK_CLASS = [\"unknown\"]\n",
    "\n",
    "VOC_COCO_CLASS_NAMES = tuple(itertools.chain(VOC_CLASS_NAMES, T2_CLASS_NAMES, T3_CLASS_NAMES, T4_CLASS_NAMES, UNK_CLASS))\n",
    "print(VOC_COCO_CLASS_NAMES)\n",
    "\n",
    "CLASSES = list(VOC_COCO_CLASS_NAMES)\n",
    "# colors for visualization\n",
    "COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
    "          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfacfb-c10a-4f22-8252-b262991fea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some utils\n",
    "\n",
    "### You can choose confidence: the default value of confidence is 0.7\n",
    "def filter_boxes(scores, boxes, confidence=0.7, apply_nms=True, iou=0.5):\n",
    "    keep = scores.max(-1).values > confidence\n",
    "    scores, boxes = scores[keep], boxes[keep]\n",
    " \n",
    "    if apply_nms:\n",
    "        top_scores, labels = scores.max(-1)\n",
    "        keep = batched_nms(boxes, top_scores, labels, iou)\n",
    "        scores, boxes = scores[keep], boxes[keep]\n",
    " \n",
    "    return scores, boxes\n",
    "\n",
    "@torch.no_grad()\n",
    "def viz(model, criterion, data_loader, dataset, device, output_dir='./output'):\n",
    "    import numpy as np\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model.eval()\n",
    "    criterion.eval()\n",
    " \n",
    "    metric_logger = MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('class_error', SmoothedValue(window_size=1, fmt='{value:.2f}'))\n",
    "\n",
    "    use_topk = True\n",
    "    num_obj = 20\n",
    "    for batch_idx, (samples, targets) in enumerate(tqdm(data_loader)):\n",
    "        if batch_idx >=10:\n",
    "            break\n",
    "        samples = samples.to(device)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        top_k = len(targets[0]['boxes'])\n",
    "\n",
    "        # outputs = model(samples)\n",
    "        # indices = outputs['pred_logits'][0].softmax(-1)[..., 1].sort(descending=True)[1][:top_k]\n",
    "        # predicted_boxes = torch.stack([outputs['pred_boxes'][0][i] for i in indices])\n",
    "        # logits = torch.stack([outputs['pred_logits'][0][i] for i in indices])\n",
    "        # scores_softmax = logits.softmax(-1)[:, :-1]\n",
    "        # labels = scores_softmax.argmax(axis=1)\n",
    "        # scores = scores_softmax.max(-1).values\n",
    "\n",
    "        outputs = model(samples)\n",
    "        probas = outputs['pred_logits'].softmax(-1)[0, :, :-1].cpu()\n",
    "        # probas = outputs['pred_logits'].softmax(-1)[0, :, :].cpu()\n",
    "        pred_objs = outputs['pred_obj'].softmax(-1)[0, :].cpu()\n",
    "        predicted_boxes = outputs['pred_boxes'][0,].cpu()\n",
    "        scores, predicted_boxes = filter_boxes(probas, predicted_boxes)\n",
    "        labels = scores.argmax(axis=1)\n",
    "        scores = scores.max(-1).values\n",
    "\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(10,3), dpi=200)\n",
    "    \n",
    "        # Ori Picture\n",
    "        plot_ori_image(\n",
    "            samples.tensors[0:1],\n",
    "            ax[0], \n",
    "            plot_prob=False,\n",
    "        )\n",
    "        ax[0].set_title('Original Image')\n",
    "\n",
    "        # Pred results\n",
    "        # if not control the number of labels\n",
    "        if not use_topk:\n",
    "            plot_prediction(\n",
    "                samples.tensors[0:1], \n",
    "                scores[-num_obj:], \n",
    "                predicted_boxes[-num_obj:].detach().cpu(), \n",
    "                labels[-num_obj:], \n",
    "                ax[1], \n",
    "                plot_prob=False,\n",
    "                dataset=dataset,\n",
    "            )\n",
    "        # if control the number of labels\n",
    "        if use_topk:\n",
    "            plot_prediction(\n",
    "                samples.tensors[0:1], \n",
    "                scores[-top_k:], \n",
    "                predicted_boxes[-top_k:], \n",
    "                labels[-top_k:], \n",
    "                ax[1], \n",
    "                plot_prob=False,\n",
    "                dataset=dataset,\n",
    "            )\n",
    "        ax[1].set_title('Prediction (Ours)')\n",
    " \n",
    "        # GT Results\n",
    "        plot_prediction(\n",
    "            samples.tensors[0:1], \n",
    "            torch.ones(targets[0]['boxes'].shape[0]), \n",
    "            targets[0]['boxes'].detach().cpu(), \n",
    "            targets[0]['labels'],\n",
    "            ax[2], \n",
    "            plot_prob=False,\n",
    "            dataset=dataset,\n",
    "        )\n",
    "        ax[2].set_title('GT')\n",
    " \n",
    "        for i in range(3):\n",
    "            ax[i].set_aspect('equal')\n",
    "            ax[i].set_axis_off()\n",
    " \n",
    "        plt.savefig(os.path.join(output_dir, f'img_{int(targets[0][\"image_id\"][0])}.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2771dd50-8f86-4e04-a9fd-dc0d2e652490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(ax, img, norm):\n",
    "    if norm:\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = (img * 255)\n",
    "    img = img.astype('uint8')\n",
    "    ax.imshow(img)\n",
    "\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(-1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=-1)\n",
    "    \n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32).to(out_bbox)\n",
    "    return b\n",
    "\n",
    "def plot_prediction(image, scores, boxes, labels, ax=None, plot_prob=True, dataset='OWOD'):    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    plot_results(image[0].permute(1, 2, 0).detach().cpu().numpy(), scores, boxes, labels, ax, plot_prob=plot_prob, dataset=dataset)\n",
    "\n",
    "def plot_ori_image(image, ax=None, plot_prob=False):    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    plot_results(image[0].permute(1, 2, 0).detach().cpu().numpy(), None, None, None, ax)\n",
    "\n",
    "def plot_results(pil_img, scores, boxes, labels, ax, plot_prob=True, norm=True, dataset='OWOD'):\n",
    "    from matplotlib import pyplot as plt\n",
    "    h, w = pil_img.shape[:-1]\n",
    "    # w, h = pil_img.shape[:-1]\n",
    "    image = plot_image(ax, pil_img, norm)\n",
    "    colors = COLORS * 100\n",
    "    if boxes is not None:\n",
    "        boxes = [rescale_bboxes(boxes[i], [w, h]).cpu() for i in range(len(boxes))]\n",
    "        for sc, cl, (xmin, ymin, xmax, ymax), c in zip(scores, labels, boxes, colors):\n",
    "            ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                       fill=False, color=c, linewidth=2))\n",
    "            # print(dataset, cl)\n",
    "            # text = f'{CLASSES[str(dataset)][cl]}: {sc:0.2f}'\n",
    "            text = f'{CLASSES[cl]}: {sc:0.2f}'\n",
    "            ax.text(xmin, ymin, text, fontsize=5, bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "    ax.grid('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c297634-519a-4c1b-b0af-44ea8e8ddb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, criterion, postprocessors, exemplar_selection = build(args)\n",
    "model.to(torch.device(args.device))\n",
    "\n",
    "print('Initialized from the pre-training model')\n",
    "checkpoint = torch.load(args.pretrain, map_location='cpu')\n",
    "state_dict = checkpoint['model']\n",
    "msg = model.load_state_dict(state_dict, strict=False)\n",
    "print(msg)\n",
    "args.start_epoch = checkpoint['epoch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2054ea90-7854-4a7b-b28a-3fe57479d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_val = get_datasets(args)\n",
    "sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
    "\n",
    "data_loader_val = DataLoader(dataset_val, args.batch_size, sampler=sampler_val,\n",
    "                             drop_last=False, collate_fn=collate_fn, num_workers=args.num_workers,\n",
    "                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c400ba-86bc-4d31-a7a4-f628c37df201",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(model, criterion, data_loader_val, args.dataset, args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1562e15a-a3c2-42e2-b167-53b4463f174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa304108-1f66-4552-b31f-2d511eb6855f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prob",
   "language": "python",
   "name": "prob"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
